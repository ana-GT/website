<!DOCTYPE html>

<!-- paulirish.com/2008/conditional-stylesheets-vs-css-hacks-answer-neither/ -->
<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js lt-ie9 lt-ie8" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js lt-ie9" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
  <meta charset="utf-8" />

  <!-- Set the viewport width to device width for mobile -->
  <meta name="viewport" content="width=device-width" />

  <title>Ana C. Huam&aacute;n Quispe</title>
  
  <!-- Included CSS Files (Compressed) -->
  <link rel="stylesheet" href="stylesheets/foundation.min.css">
  <link rel="stylesheet" href="stylesheets/main.css">
  <link rel="stylesheet" href="stylesheets/app.css">

  <script src="javascripts/modernizr.foundation.js"></script>
  
  <!-- Google fonts -->
<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300|Playfair+Display:400italic' rel='stylesheet' type='text/css' />

  <!-- IE Fix for HTML5 Tags -->
  <!--[if lt IE 9]>
    <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

</head>
<body>

			<!-- Header Logo -->
      <div class="row">      
      <!-- <a href="index.html"><img src="images/logo.png" alt="desc" class="header_logo" /></a> -->     
     <h3>A. C. Huam&aacute;n Quispe</h3>
      </div>
      
      
     <div class="row page_wrap" style="margin-top:-2px">
     <!-- page wrap -->
     <div class="twelve columns">
      <!-- page wrap -->
      
    	<!-- Navigation Bar -->   
       <div class="row">  
      
        <div class="twelve columns header_nav" style="margin-bottom:0; box-shadow: none">
        
          <div class="twelve columns">
            <ul id="menu-header" class="nav-bar horizontal">
            
            <li class=""><a href="index.html">Home</a></li>              
            <li class="active"><a href="research.html">Research</a></li>  
            <li class=""><a href="publications.html">Publications</a></li>
            <li class=""><a href="contact.html">Contact</a></li>
            <li class=""><a href="code.html">Code</a></li>
            <li class=""><a href="tutorials.html">Tutorials</a></li>
            <li class=""><a href="about.html">About</a></li>

            </ul><script type="text/javascript">
           //<![CDATA[
           $('ul#menu-header').nav-bar();
            //]]>
            </script>

          </div>
          </div>          
        </div>
				<!-- END Navigation Bar -->

      <!-- Slider images -->
        <div class="row show-for-large-up">
           <div class="twelve columns">
            <div id="featured"><img src="images/slide0_crichton_pickup.png" alt="Crichton pickup" width="960" height="250" />
<img src="images/slide1_ICHR2014.png" alt="ICHR 2014" width="960" height="250" /><img src="images/baxter_asu_grasps_1.png" alt="Crichton Jr. picking up objects at ASU" width="960" height="250" /><img src="images/slide2_multiplePaths.png" alt="IROS 2013" width="960" height="250" /><img src="images/slide4_apcDogFood.png" alt="APC Dog Food Trial" width="960" height="250" /></div>
           </div>
           </div>
        </div>
      <!-- END Slider images -->
      
      <!-- Research -->
      <div class="row"> 
      <div class="twelve columns">

				<h4>Research</h4>

                                <p>My work involves the full pipeline of robot manipulation, so here you will find a wide amount of various things I
do related to each module which allows Crichton to manipulate objects:</p>

						<ul>
							<li><a href="#pouring3Objects">Pouring in different locations (because it is not always the center!)</a></li>
							<li><a href="#pickAndPlaceRelaxed">Robot picks and place to a table, on top of a box and inside a box</a></li>
							<li><a href="#robotPouring">Robot pours</a></li>
							<li><a href="#objectRecognition">Robot sees, robot recognizes</a></li>
							<li><a href="#generalization">Generalization: Robots galore!</a></li>
							<li><a href="#efficientTask">Efficient Manipulation Planning using Task Goals</a></li>
							<li><a href="#sq">Grasping unknown objects using superquadrics approximation</a></li>
							<li><a href="#nss">Path Planning for Redundant Robotic Arms</a></li>
					</ul>


				<h4>Side Project of the Semester (Spring 2015)</h4>
						<ul>
							<li><a href="#cabinet">The Robot vs the Cabinet</a></li>
					</ul>


				<h4>Various previous projects</h4>
						<ul>
							<li><a href="#tortuninjaProject">Robot exploration under human supervision</a></li>
					</ul>		

			<!-- Horizontal Line -->       
			<hr />	


			<h5><a name="pouring3Objects">Crichton pours from 3 objects into a bowl at different places on a table</a></h5>
				<table border="1">
				<tr>
						<td><video width="640" height="480" controls>
  <source src="media/pouring_april_25_2016_3objects.mp4" type="video/mp4"></video></td>
						<td>Tests with 3 different objects (white cup, Pringles and mustard). The objects start at 3 different locations and end up in 6 goal places for the bowl (showing only 4 examples per each due to lack of space). If for some reason this video does not play here, you can see the YouTube version <a href="https://www.youtube.com/watch?v=HncXhkcdo9Y">here</a></td>
				</tr>
				</table> 


			<h5><a name="PickAndPlaceRelaxed">Crichton picking and placing objects on a table, on top of a box and inside a box!</a></h5>
				<table border="1">
				<tr>
						<td><video width="640" height="480" controls>
  <source src="media/pickAndPlaceRelaxed.mp4" type="video/mp4"></video></td>
						<td>Tests with 10 objects (the video shows 4, I have to find the time to edit the remaining 6 other clips and upload them here!): Pringles container, milk, Cheezit and Raisins box. If for some reason this video does not play here, you can see the YouTube version <a href="https://vimeo.com/163172397">here</a></td>
				</tr>
				</table> 



			<h5><a name="robotPouring">Crichton pours from 3 different objects!</a></h5>
				<table border="1">
				<tr>
						<td><td><video width="640" height="480" controls>
  <source src="media/pouring1_2016_04_08.mp4" type="video/mp4"></video></td>
						<td>Tests with 3 objects: Pringles container, Soft scrub and Raisins box. If for some reason this video does not play here, you can see the YouTube version <a href="https://youtu.be/IpT1uZO4MSw">here</a>. More description coming up soon!</td>
				</tr>
				</table> 

			<h5><a name="objectRecognition">Crichton recognizing 42 objects!</a></h5>
				<table border="1">
				<tr>
						<td><iframe width="400" height="300" src="https://www.youtube.com/embed/H1dqGsmAtLM?list=PL0_FFtSIbUNUhWShdd6sGyoz9qICKSPNF" frameborder="0" allowfullscreen></iframe></td>
						<td>Humans manipulate objects everyday and unconsciously we use our experience to
help us decide how to handle objects. While we do not have the exact information of every object (i.e. detailed 3D models), we certainly
know "something" about most objects we face. For instance, if we see a cup we will likely try to grasp it from the side and keep it upright.
This video shows the results of our teaching Crichton to recognize 42 different household objects (30 of them from the YCB dataset). By recognizing
the objects, Crichton in turn can access some pre-stored information, such as a general description of the object and general information
about affordances, which is useful for the subsequent step of manipulation planning.</td>
				</tr>
				</table> 


			<!-- Horizontal Line -->       
			<hr />	

			<h5><a name="generalization">Hi Baxter!</a></h5>
				<table border="1">
				<tr>
						<td><iframe width="400" height="300" src="https://www.youtube.com/embed/LiPcuwIFLjo?list=PL0_FFtSIbUNUhWShdd6sGyoz9qICKSPNF" frameborder="0" allowfullscreen></iframe></td>
						<td>As much as I love Crichton, it is evident to me that he is not the only robot
on Earth. We decided to test his pipeline on another platform and we got the great chance to paid a visit to Dr. Ben Amor at Arizona
State University. Dr. Ben Amor happened to have a Baxter so we set to transfer some of Crichton manipulation code to the said Baxter
(a.k.a. Cricthon Jr.) and we got some neat results. I was only there for the week so I am looking forward to have more time to
play around with the red robot in the future. Besides the joy of working with another platform, it is worth noticing that the algorithms
we design are hardware agnostic, hence in theory they should run in any robot, as was the case here.</td>
				</tr>
				</table> 


			<!-- Horizontal Line -->       
			<hr />	

			<h5><a name="efficientTask">Efficient Manipulation Planning using Task Goals</a></h5>
				<table border="1">
				<tr>
						<td><iframe width="400" height="300" src="https://www.youtube.com/embed/3Z4I2Ha1ko0" frameborder="0" allowfullscreen></iframe></td>
						<td>Our recent work submitted to IROS! In order to grasp an object you have to choose among potentially infinite possibilities, particularly if your arm is redundant. In this work, we investigate how to use the end-comfort effect to help us choose a solution quickly and effectively.</td>
				</tr>
				</table> 

			<!--  Benchmark Manipulation Tasks-->
			<h5><a name="sq">Grasping Unknown Objects using online Superquadrics Approximation</a></h5>
				<table border="1">
				<tr>
						<td><iframe width="400" height="300" src="https://www.youtube.com/embed/7vFIv2wl-Mk" frameborder="0" allowfullscreen></iframe></td>
						<td>I have to add more details here but in short: Does your robot have what it takes to grasp unknown objects in a fast and efficient manner? 
This work will be presented at ICRA 2015 in May</td>
				</tr>
				</table> 


			<!--  Path Planning for Redundant Arms -->
			<h5><a name="nss">Path Planning for Redundant Robotic Arms</a></h5>
				<table border="1">
				<tr>
						<td><iframe src="http://player.vimeo.com/video/61897631" width="400" height="300" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></td>
						<!--<td><embed src="http://blip.tv/play/AYOP8XMA?p=1" type="application/x-shockwave-flash" width="320" height="250" wmode="transparent" allowscriptaccess="always" allowfullscreen="true" ></embed></td> -->
						<td>Redundancy is a desired feature in robotic arms. Why? Well, if you have more degrees of freedom (DOF) than you need allows more than
one possible way to accomplish a manipulation task. However, this flexibility also arises questions: Which of all alternatives should we choose? Is it possible
to list all the possibilities so we can choose "the best"? I propose a determistic method to express these different alternatives by means of discretizing the
nullspace of the arm and searching through it. By using diverse heuristic functions, we evaluate the configurations and choose the best depending on our
requirements.</td>
				</tr>
				</table> 



			<!-- Horizontal Line -->       
			<hr />	

			<h5><a name="cabinet">The Robot vs the Cabinet</a></h5>
				<table border="1">
				<tr>
						<td><iframe width="400" height="300" src="https://www.youtube.com/embed/GzP4uYzrHCM" frameborder="0" allowfullscreen></iframe></td>
						<td>Bin picking, although an inherently simple problem, is not that easy to solve for a robot with such long limb as ours (not to mention his
freaking long fingers). Whenever I have free time, I go away from my benchmarking general manipulation problems and investigate how to efficiently generate
plans for Crichton to become a future warehouse robot :0}</td>
				</tr>
				</table> 


			<!-- Horizontal Line -->       
			<hr />	

			<!--  Robot Exploration under Human Supervision -->
			<h5><a name="tortuninjaProject">Dynamic Signaling of  Robot Teams under Human Supervision</a></h5>
				<table border="1">
				<tr>
						<td><iframe src="http://player.vimeo.com/video/61927303" width="400" height="300" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></td>
						<td>
						How many robots can a human operator reasonably supervise? While many people agree that the number depends on the task
						to be performed, it is natural that the greater the number of robots the more attention the human supervisor requires. In this project,
						we implement a mock environment in which 2 robots search for a red object. Once one of them finds it, the robot will approach it to
						verify the object's identity and then it will fire a visual dynamic signal (moving back and forth) so it catches the supervisor's attention.
						Simulation made with the Gazebo simulator coupled with ROS to access simulated Kinect and odometry data.
						</td>
				</tr>
				</table> 

			<!-- Horizontal Line -->       
			<hr />	

      </div>
      </div>
      <!-- END Research -->   
      

      <div class="row">
      <div class="twelve columns">
          <ul id="menu3" class="footer_menu horizontal">
            <li class=""><a href="index.html">Home</a></li>
          </ul>
      </div>
      </div>
		  
		  <script type="text/javascript">
          //<![CDATA[
          $('ul#menu3').nav-bar();
          //]]>
          </script>

      </div>

    </div><!-- end page wrap) -->
    <!-- Included JS Files (Compressed) -->
    <script src="javascripts/foundation.min.js" type="text/javascript">
</script> <!-- Initialize JS Plugins -->
     <script src="javascripts/app.js" type="text/javascript">
</script>
  
</body>
</html>
